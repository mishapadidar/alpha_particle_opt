{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tested-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath,bm}')\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "# matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "accomplished-eligibility",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s_pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-d2191b955f02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstz_inits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stz_inits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvpar_inits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vpar_inits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ms_pdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's_pdf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0ms_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ms_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's_std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 's_pdf'"
     ]
    }
   ],
   "source": [
    "infile = \"data_test_boozer.pickle\"\n",
    "indata = pickle.load(open(infile,'rb'))\n",
    "c_times = indata['c_times']\n",
    "mu_crit =indata['mu_crit']\n",
    "modB = indata['modB']\n",
    "stz_inits = indata['stz_inits'] \n",
    "vpar_inits = indata['vpar_inits']\n",
    "s_pdf = indata['s_pdf']\n",
    "s_mean = indata['s_mean']\n",
    "s_std = indata['s_std']\n",
    "mu = indata['mu']\n",
    "mu_mean = indata['mu_mean']\n",
    "mu_std = indata['mu_std']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "exclusive-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_func = lambda t:  3.5*np.exp(-2*t/tmax)\n",
    "energy = energy_func(c_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-disposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "operating-exemption",
   "metadata": {},
   "source": [
    "# 1. Control Variate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-claim",
   "metadata": {},
   "source": [
    "## 1.1 Control variate using s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "sudden-stevens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean 0.007081968741085875\n",
      "MC std 0.004490661214463294\n",
      "CV mean 0.007122153702638998\n",
      "CV std 0.004207876413584632\n",
      "Reduction in standard deviation 0.06297175123518184\n",
      "Effective increase in number of samples 1.1389237052071695\n"
     ]
    }
   ],
   "source": [
    "s = stz_inits[:,0]\n",
    "s_mean = 0.20596158592366795\n",
    "s_var =  0.025053175240927983\n",
    "s_std = np.sqrt(var_s)\n",
    "rho = np.corrcoef(s,c_times)[0,1]\n",
    "c = -rho* np.std(c_times)/s_std\n",
    "# control variate\n",
    "cv = c_times + c*(s-s_mean)\n",
    "print('MC mean',np.mean(c_times))\n",
    "print('MC std',np.std(c_times))\n",
    "print('CV mean',np.mean(cv))\n",
    "print('CV std',np.std(cv))\n",
    "print(\"Reduction in standard deviation\",1-np.std(cv)/np.std(c_times))\n",
    "alpha = np.std(cv)/np.std(c_times)\n",
    "print(\"Effective increase in number of samples\",1/alpha**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-monroe",
   "metadata": {},
   "source": [
    "## 1.2 Control variate using mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "allied-algeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean 0.007081968741085875\n",
      "MC std 0.004490661214463294\n",
      "CV mean 0.007096295667732925\n",
      "CV std 0.003934286015910921\n",
      "Reduction in standard deviation 0.12389605271500503\n",
      "Effective increase in number of samples 1.3028329263181768\n"
     ]
    }
   ],
   "source": [
    "mu_mean = 9139072590066.031 \n",
    "mu_std = 4121149626307.4717\n",
    "rho = np.corrcoef(mu,c_times)[0,1]\n",
    "c_times_std = np.std(c_times)\n",
    "c = -rho*c_times_std/mu_std\n",
    "# control variate\n",
    "cv = c_times + c*(mu-mu_mean)\n",
    "print('MC mean',np.mean(c_times))\n",
    "print('MC std',np.std(c_times))\n",
    "print('CV mean',np.mean(cv))\n",
    "print('CV std',np.std(cv))\n",
    "print(\"Reduction in standard deviation\",1-np.std(cv)/np.std(c_times))\n",
    "alpha = np.std(cv)/np.std(c_times)\n",
    "print(\"Effective increase in number of samples\",1/alpha**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-pleasure",
   "metadata": {},
   "source": [
    "## 1.3 Control Variate using s and mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "minus-tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean 0.007081968741085875\n",
      "MC std 0.004490661214463294\n",
      "CV mean 0.007134901433288679\n",
      "CV std 0.003634326055706806\n",
      "Reduction in standard deviation 0.1906924432416427\n",
      "Effective increase in number of samples 1.5267671563780767\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use both s and mu as control variates. In this formulation we take a shortcut to building the control variate. \n",
    "We first find the optimal estimator when mu is a control variate,\n",
    "    cv1 = Y + c1*(mu - mean(mu))\n",
    "    c1 = -corr(mu,y)*np.std(c_times)/std(mu)\n",
    "Then, with c1 fixed, we use S as a control variate with cv1. i.e. we use the control variate\n",
    "    cv2 = cv1 + c2*(s - mean(s))\n",
    "    c2 = -corr(s,cv1)*np.std(cv1)/std(s)\n",
    "\"\"\"\n",
    "rho1 = np.corrcoef(mu,c_times)[0,1]\n",
    "c1 = -rho1*np.std(c_times)/mu_std\n",
    "cv1 = c_times + c1*(mu-mu_mean) \n",
    "rho2 = np.corrcoef(s,cv1)[0,1]\n",
    "c2 = -rho2*np.std(cv1)/s_std\n",
    "cv = cv1 + c2*(s-s_mean)\n",
    "print('MC mean',np.mean(c_times))\n",
    "print('MC std',np.std(c_times))\n",
    "print('CV mean',np.mean(cv))\n",
    "print('CV std',np.std(cv))\n",
    "print(\"Reduction in standard deviation\",1-np.std(cv)/np.std(c_times))\n",
    "alpha = np.std(cv)/np.std(c_times)\n",
    "print(\"Effective increase in number of samples\",1/alpha**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "seven-guatemala",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean 0.007081968741085875\n",
      "MC std 0.004490661214463294\n",
      "CV mean 0.007134635241801238\n",
      "CV std 0.003634261210564699\n",
      "Reduction in standard deviation 0.19070688324034457\n",
      "Effective increase in number of samples 1.5268216402529167\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use both s and mu as control variates. This is the proper way to construct the control variate.\n",
    "\n",
    "If Y is the confinement times and X = (mu,s) then we form the control variate\n",
    "    cv = Y + (X - X_mean) @ c\n",
    "where c satisfies\n",
    "    Cov(X,X) @ c = - Cov(Y,X)\n",
    "Since we know the standard deviations of mu and s, we can input those directly into this equation and simplify a bit. \n",
    "Then this equation only relies on correlation coefficients which are scale free. This helps avoid the error that arises\n",
    "in estimation of coefficients. In short, we find c via the linear system A @ c = - b where\n",
    "A = [[mu_std, s_std*corr(mu,s)] \n",
    "    [mu_std*corr(mu,s), s_std]]\n",
    "b = y_std *[corr(mu,y),corr(s,y)]\n",
    "\"\"\"\n",
    "Sigma = np.array([[mu_std,s_std*np.corrcoef(s,mu)[0,1]],[mu_std*np.corrcoef(s,mu)[0,1],s_std]])\n",
    "rho_s_c = np.corrcoef(s,c_times)[0,1]\n",
    "rho_mu_c = np.corrcoef(mu,c_times)[0,1]\n",
    "rhs = np.std(c_times)*np.array([rho_mu_c,rho_s_c])\n",
    "c = -np.linalg.solve(Sigma,rhs)\n",
    "X = np.vstack((mu,s)).T\n",
    "X_mean = np.array([mu_mean,s_mean])\n",
    "cv = c_times + (X-X_mean) @ c\n",
    "print('MC mean',np.mean(c_times))\n",
    "print('MC std',np.std(c_times))\n",
    "print('CV mean',np.mean(cv))\n",
    "print('CV std',np.std(cv))\n",
    "print(\"Reduction in standard deviation\",1-np.std(cv)/np.std(c_times))\n",
    "alpha = np.std(cv)/np.std(c_times)\n",
    "print(\"Effective increase in number of samples\",1/alpha**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-tracker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "british-usage",
   "metadata": {},
   "source": [
    "# Loss Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concrete-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loss profile\n",
    "# fig,ax = plt.subplots(nrows=1,ncols=1,figsize = (10,8))\n",
    "\n",
    "# # make the loss profile\n",
    "# times = np.linspace(1e-7,tmax,100)\n",
    "# loss_profile = np.array([np.mean(c_times< t) for t in times]) \n",
    "# plt.plot(times,loss_profile,linewidth=3,label='in-sample')\n",
    "# loss_profile = np.array([np.mean(c_times< t) for t in times]) \n",
    "# plt.plot(times,loss_profile,linewidth=3,label='out-of-sample')\n",
    "\n",
    "# plt.title(\"Loss Profile\")\n",
    "# plt.xlabel('time ')\n",
    "# plt.ylabel(\"Loss Fraction\")\n",
    "# plt.xscale('log')\n",
    "# bottom,top =plt.ylim(-0.02,1.02)\n",
    "# plt.vlines(tmax,bottom,top,linestyle='--',color='k',linewidth=2,label='tmax')\n",
    "# plt.xlim(1e-7,2*tmax)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
